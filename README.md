# Spider

![language](https://img.shields.io/badge/language-Python-blue)
![license](https://img.shields.io/badge/License-MIT-red)
![package](https://img.shields.io/badge/package-requests|DrissionPage-orange)

This repository records the simple code snippets I coded during my learning of web crawling techniques.Some simple crawler code will be updated from time to time, I hope it can help you，good luck！

仓库记录着我在学习爬虫技术过程中留下的简单代码段。会不定时更新，希望能帮到你。

---

## 相关文件说明

- [**SimPrograms**](https://github.com/zhuruili/Spider/tree/main/SimPrograms)  
  记录自己学习爬虫所留下的简单程序，该文件夹下的爬虫程序的特点是'简单'，基本上都是一个Python文件直接运行即可。
- [**Spi_DataSave**](https://github.com/zhuruili/Spider/tree/main/Spi_DataSave)  
  保存部分爬取的内容，体量比较小的数据集我会同步到仓库，如有需要可以直接下载。

## 内容目录

### SimPrograms

- [NBA球员top50](https://github.com/zhuruili/Spider/blob/main/SimPrograms/spi_NBA.py)  
  NBA 球员top50数据--文件：spi_NBA.py。基于requests获取数据，使用xpath表达式提取数据。代码结构很清晰也比较短，适合新手学习。
- [b站视频信息](https://github.com/zhuruili/Spider/blob/main/SimPrograms/spi_bilibili_rsc.py)  
  哔哩哔哩视频信息自动化爬取--文件：spi_bilibili_rsc.py。基于DrissionPage实现自动化数据抓取，只是一个很简单的Demo抓取的内容也只是搜索视频后看到的推送内容。
- 某宝商品数据自动化采集--文件：spi_Taobao.py
- JD商品评论自动化爬取--文件：spi_JD_comments.py

### DataSaved

仓库中所保存的程序爬取所得到的数据集可能会随时变动，因此就不在此处列表展示了，感兴趣的话可以直接到存放数据集的文件夹下查看其具体内容。

---

> [!Important]
> 注意：仓库代码仅供学习交流使用，不可用于非法用途！
